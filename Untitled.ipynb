{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d0b625-45ea-4efb-a49d-baef9fe70e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks\n",
    "from env import train\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5deb8319-2b06-46f1-bd3c-e1342a9b5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 198.8600006610155 average time: 114.85 best_reward: 421.4000016450882\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 191.10500072948633 average time: 112.0 best_reward: 421.300002142787\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 225.9850007493049 average time: 132.0 best_reward: 492.60000213980675\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 218.57000064104795 average time: 113.2 best_reward: 448.1000020876527\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 298.76000080518423 average time: 155.5 best_reward: 596.5000034943223\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 231.70500081516803 average time: 169.2 best_reward: 492.3000031262636\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 283.5850009869784 average time: 142.7 best_reward: 728.6000030115247\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 80000 / 500000\n",
      "average reward: 355.7500010214746 average time: 183.9 best_reward: 984.9000034406781\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 295.7700010530651 average time: 311.2 best_reward: 594.7000013664365\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 221.02000058926643 average time: 104.4 best_reward: 523.3000005930662\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 283.34500107243656 average time: 143.35 best_reward: 728.5000028982759\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 404.22500176765027 average time: 184.25 best_reward: 730.0000026002526\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 327.6800012480468 average time: 201.0 best_reward: 813.700003311038\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 274.3300012178719 average time: 128.65 best_reward: 447.5000020265579\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 279.3850011780858 average time: 128.35 best_reward: 728.0000034123659\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 309.20500142276285 average time: 136.4 best_reward: 576.2000024393201\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 370.3750016152859 average time: 159.1 best_reward: 729.8000039830804\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 433.3150016952306 average time: 189.8 best_reward: 813.700000859797\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 382.3100017402321 average time: 154.45 best_reward: 577.0000022128224\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 429.9250018358231 average time: 194.8 best_reward: 814.0000032931566\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 210000 / 500000\n",
      "average reward: 459.04000177942214 average time: 200.35 best_reward: 986.800004683435\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 424.82000177390876 average time: 177.0 best_reward: 729.0000036805868\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 339.38500126600263 average time: 174.9 best_reward: 726.6000026538968\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 450.85500183068217 average time: 195.0 best_reward: 730.3000023365021\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 305.75000114925206 average time: 175.05 best_reward: 730.0000028535724\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 380.61000158935786 average time: 248.0 best_reward: 730.0000025257468\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 415.74000197276473 average time: 184.35 best_reward: 722.2000040411949\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 391.21000180095433 average time: 195.1 best_reward: 528.4000018313527\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 409.5150017697364 average time: 175.7 best_reward: 814.6000025346875\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 519.7150021038949 average time: 247.45 best_reward: 729.7000021636486\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 581.4500027693808 average time: 247.3 best_reward: 815.2000033780932\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 393.6150016374886 average time: 156.35 best_reward: 731.8000030815601\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 437.70500192902983 average time: 181.2 best_reward: 816.3000039607286\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 340000 / 500000\n",
      "average reward: 524.4050021879375 average time: 230.8 best_reward: 986.4000032320619\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 269.2350011508912 average time: 317.8 best_reward: 525.7000022530556\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 360000 / 500000\n",
      "average reward: 431.6200017519295 average time: 211.0 best_reward: 981.8000031635165\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 370000 / 500000\n",
      "average reward: 529.2400022301823 average time: 289.8 best_reward: 985.9000048264861\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 465.76500178948044 average time: 254.8 best_reward: 987.6000041291118\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 390000 / 500000\n",
      "average reward: 437.58000177741053 average time: 242.05 best_reward: 983.400005504489\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 258.545000968501 average time: 318.4 best_reward: 594.0000024735928\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 364.5800014317036 average time: 299.8 best_reward: 983.3000006973743\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 375.0600014850497 average time: 190.85 best_reward: 986.0000026673079\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 346.8350014910102 average time: 165.1 best_reward: 727.9000037759542\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 382.7850016012788 average time: 212.4 best_reward: 981.9000024348497\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 444.0250021275133 average time: 262.45 best_reward: 866.8000039532781\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 420.45000174678864 average time: 264.6 best_reward: 813.9000031799078\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 446.9650018341839 average time: 271.8 best_reward: 986.60000243783\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 384.00000154264274 average time: 265.75 best_reward: 814.2000033259392\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 392.32000191845 average time: 161.1 best_reward: 986.1000062972307\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 315.3350013256073 average time: 198.05 best_reward: 727.7000033706427\n"
     ]
    }
   ],
   "source": [
    "train('./None', activation_function = torch.nn.Tanh, orthagonal_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9cdd77-05aa-477f-954c-03136e2ef5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 253.91500056572258 average time: 146.2 best_reward: 491.8000001832843\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 224.19500066563486 average time: 123.3 best_reward: 492.5000017359853\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 239.8400007110089 average time: 139.1 best_reward: 421.20000172406435\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 236.54000078402458 average time: 138.55 best_reward: 444.5000018104911\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 238.28500062823295 average time: 139.15 best_reward: 488.5000010058284\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 210.61500063315034 average time: 122.95 best_reward: 415.7000023648143\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 241.9300005033612 average time: 174.5 best_reward: 416.10000060498714\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 172.4950005494058 average time: 87.1 best_reward: 421.6000020056963\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 221.7500006724149 average time: 107.1 best_reward: 448.0000013932586\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 196.42000052966176 average time: 107.5 best_reward: 528.1000023856759\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 249.04500075653195 average time: 123.8 best_reward: 493.800001911819\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 120000 / 500000\n",
      "average reward: 356.2400012176484 average time: 171.8 best_reward: 985.7000029534101\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 258.7300007082522 average time: 121.1 best_reward: 529.6000021696091\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 252.7450009301305 average time: 125.0 best_reward: 448.0000024959445\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 340.92000128030776 average time: 161.8 best_reward: 525.8000015169382\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 347.2450014218688 average time: 157.35 best_reward: 577.8000027909875\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 343.64500135444104 average time: 178.65 best_reward: 728.400002270937\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 180000 / 500000\n",
      "average reward: 415.96000177562235 average time: 180.9 best_reward: 985.7000043541193\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 427.80000192523005 average time: 185.6 best_reward: 726.1000029295683\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 434.5150018531829 average time: 291.65 best_reward: 647.200002759695\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 322.6750013642013 average time: 221.3 best_reward: 647.4000030085444\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 344.2000013325363 average time: 198.7 best_reward: 722.7000036984682\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 290.2200009893626 average time: 157.55 best_reward: 529.700002335012\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 481.0050021670759 average time: 252.95 best_reward: 729.4000034332275\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 361.535001437366 average time: 158.65 best_reward: 596.2000025585294\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 418.8400018505752 average time: 182.85 best_reward: 841.0000039562583\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 417.28500211797655 average time: 171.35 best_reward: 731.3000041022897\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 489.37500204667447 average time: 385.4 best_reward: 731.6000028699636\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 396.90000166222455 average time: 208.65 best_reward: 647.1000030338764\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 455.8200017232448 average time: 247.7 best_reward: 729.0000022873282\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 475.5150020904839 average time: 234.45 best_reward: 757.6000017151237\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 320000 / 500000\n",
      "average reward: 388.95000156164167 average time: 182.25 best_reward: 981.2000034302473\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 330000 / 500000\n",
      "average reward: 459.21000175848604 average time: 218.85 best_reward: 985.3000036627054\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 396.16500189825894 average time: 158.75 best_reward: 730.2000038102269\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 381.3800018388778 average time: 152.9 best_reward: 730.1000043004751\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 381.96000154912474 average time: 276.1 best_reward: 729.7000034600496\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 370000 / 500000\n",
      "average reward: 395.54500166140497 average time: 179.95 best_reward: 984.7000045180321\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 382.6450016785413 average time: 172.3 best_reward: 983.3000051006675\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 390000 / 500000\n",
      "average reward: 502.04000200629235 average time: 230.7 best_reward: 984.3000013232231\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 400000 / 500000\n",
      "average reward: 571.0100021570921 average time: 302.2 best_reward: 985.1000023037195\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 347.4100012883544 average time: 179.15 best_reward: 986.2000037804246\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 516.0650021586567 average time: 236.1 best_reward: 983.9000042304397\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 430000 / 500000\n",
      "average reward: 498.5050021611154 average time: 243.6 best_reward: 984.000003285706\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 379.7600015010685 average time: 181.9 best_reward: 984.5000015646219\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 320.4400012809783 average time: 317.35 best_reward: 722.1000030264258\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 460000 / 500000\n",
      "average reward: 429.60000166222454 average time: 293.35 best_reward: 980.9000033065677\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 412.42500177249315 average time: 208.0 best_reward: 977.0000035911798\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 637.5900028176605 average time: 314.95 best_reward: 985.6000061407685\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 400.7800017055124 average time: 197.9 best_reward: 811.700003258884\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 414.5250017881393 average time: 226.0 best_reward: 814.500004440546\n"
     ]
    }
   ],
   "source": [
    "train('./Intrins', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, intrins_reward = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67022f3e-1efa-49ca-8d19-026c0eae0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 288.07000064961613 average time: 219.7 best_reward: 727.5000011846423\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 237.25500032901763 average time: 201.65 best_reward: 414.69999987632036\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 260.11500032693147 average time: 186.95 best_reward: 419.49999929219484\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 240.46000057049096 average time: 139.4 best_reward: 576.6000024750829\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 242.23500066027046 average time: 150.85 best_reward: 524.6000018343329\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 214.16000049486757 average time: 130.65 best_reward: 491.00000102072954\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 218.4900007493794 average time: 105.0 best_reward: 492.00000128149986\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 226.49500074088573 average time: 134.7 best_reward: 447.1000027731061\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 277.64000082351265 average time: 155.35 best_reward: 576.1000031158328\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 252.330000660941 average time: 129.9 best_reward: 595.2000011876225\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 110000 / 500000\n",
      "average reward: 325.2450008101761 average time: 196.65 best_reward: 983.5000007748604\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 215.7100004926324 average time: 120.0 best_reward: 595.9000021889806\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 130000 / 500000\n",
      "average reward: 334.7250009972602 average time: 194.45 best_reward: 984.5000036507845\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 281.0500008951873 average time: 143.35 best_reward: 526.7000021710992\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 289.1450007263571 average time: 152.1 best_reward: 492.6000018417835\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 300.1600008998066 average time: 153.2 best_reward: 594.5000027641654\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 306.990000872314 average time: 152.7 best_reward: 596.400002323091\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 231.60500079020858 average time: 117.15 best_reward: 422.80000173300505\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 269.9900008182973 average time: 129.45 best_reward: 492.70000222325325\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 301.26500116474926 average time: 143.1 best_reward: 528.400002554059\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 351.5150013323873 average time: 157.6 best_reward: 577.5000011473894\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 369.61000138409435 average time: 166.95 best_reward: 602.4000029265881\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 383.25000138171015 average time: 176.05 best_reward: 730.7000034078956\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 357.08000150434674 average time: 151.2 best_reward: 731.1000031083822\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 506.89500222019853 average time: 203.65 best_reward: 815.7000030055642\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 453.04500218331816 average time: 186.55 best_reward: 727.000003375113\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 446.0750020124018 average time: 186.5 best_reward: 815.8000032901764\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 448.1700020618737 average time: 173.85 best_reward: 731.0000034719706\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 482.2400021318346 average time: 196.15 best_reward: 814.3000030145049\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 493.12000240720806 average time: 191.4 best_reward: 731.6000032871962\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 446.6900018937886 average time: 180.05 best_reward: 730.9000029340386\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 355.14000168964265 average time: 136.3 best_reward: 730.9000028222799\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 330000 / 500000\n",
      "average reward: 454.335002014786 average time: 181.05 best_reward: 987.0000037699938\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 481.34500218145547 average time: 186.95 best_reward: 811.3000031933188\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 350000 / 500000\n",
      "average reward: 464.1800020672381 average time: 180.2 best_reward: 985.500003054738\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 360000 / 500000\n",
      "average reward: 414.84000174477694 average time: 173.4 best_reward: 986.1000047326088\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 464.41000209972265 average time: 186.5 best_reward: 810.0000033825636\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 384.365001751855 average time: 160.6 best_reward: 730.000003516674\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 600.5200026821345 average time: 244.15 best_reward: 815.6000039055943\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 400000 / 500000\n",
      "average reward: 555.4950022131204 average time: 228.1 best_reward: 986.7000020891428\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 532.5200022328645 average time: 221.95 best_reward: 986.8000013232231\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 553.8000023368746 average time: 230.6 best_reward: 987.100003734231\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 405.7700018800795 average time: 152.1 best_reward: 596.8000030368567\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 464.1250019669533 average time: 205.05 best_reward: 808.7000027820468\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 550.1650025952607 average time: 219.85 best_reward: 815.6000042557716\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 456.83000181466343 average time: 191.7 best_reward: 815.5000028833747\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 540.9050022851676 average time: 216.55 best_reward: 986.0000031739473\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 468.7250018998981 average time: 216.55 best_reward: 814.4000033438206\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 546.9950025964529 average time: 219.95 best_reward: 986.500003054738\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 488.4350020624697 average time: 205.35 best_reward: 814.40000333637\n"
     ]
    }
   ],
   "source": [
    "train('./Annealing', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, annealing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbb92a4-a5be-49d8-8940-33292e55ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 231.8850003749132 average time: 189.55 best_reward: 487.0000003054738\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 249.02000081017613 average time: 136.75 best_reward: 492.20000091940165\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 245.8550007712096 average time: 137.25 best_reward: 524.600001975894\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 323.99000112600623 average time: 182.85 best_reward: 492.20000103861094\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 210.9550007622689 average time: 96.6 best_reward: 447.30000127106905\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 222.15500076636673 average time: 101.0 best_reward: 577.3000015467405\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 249.3450008071959 average time: 120.0 best_reward: 492.9000024497509\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 409.9150015767664 average time: 180.3 best_reward: 728.6000029593706\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 307.09500102065505 average time: 147.95 best_reward: 576.4000015854836\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 461.6900016833097 average time: 201.5 best_reward: 729.500003091991\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 404.42000161260364 average time: 177.2 best_reward: 594.6000007092953\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 120000 / 500000\n",
      "average reward: 433.7500017017126 average time: 202.2 best_reward: 983.0000004470348\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 465.1800020992756 average time: 196.75 best_reward: 729.6000025868416\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 449.28500206544993 average time: 193.6 best_reward: 814.7000042274594\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 150000 / 500000\n",
      "average reward: 316.6350011661649 average time: 136.35 best_reward: 985.7000049129128\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 399.56000176519154 average time: 165.45 best_reward: 731.0000027641654\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 170000 / 500000\n",
      "average reward: 519.5700022466481 average time: 248.3 best_reward: 987.4000021219254\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 180000 / 500000\n",
      "average reward: 490.4700018823147 average time: 273.6 best_reward: 986.7000025585294\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 190000 / 500000\n",
      "average reward: 567.9600022938102 average time: 252.1 best_reward: 986.7000036984682\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 200000 / 500000\n",
      "average reward: 377.05500145182015 average time: 154.4 best_reward: 985.9000054076314\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 210000 / 500000\n",
      "average reward: 547.9800025474281 average time: 234.65 best_reward: 986.500006057322\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 220000 / 500000\n",
      "average reward: 617.3050024610013 average time: 356.7 best_reward: 987.3000031560659\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 230000 / 500000\n",
      "average reward: 333.2950013950467 average time: 177.75 best_reward: 986.4000043869019\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 264.26000119559467 average time: 134.8 best_reward: 729.3000025600195\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 250000 / 500000\n",
      "average reward: 394.8500021502376 average time: 230.9 best_reward: 978.1000060364604\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 260000 / 500000\n",
      "average reward: 446.1850015502423 average time: 346.55 best_reward: 977.799999922514\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 270000 / 500000\n",
      "average reward: 591.1850021705031 average time: 418.25 best_reward: 984.600002489984\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 280000 / 500000\n",
      "average reward: 573.1600022483617 average time: 322.05 best_reward: 981.3000022172928\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 290000 / 500000\n",
      "average reward: 594.8600027736277 average time: 255.55 best_reward: 986.9000039696693\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 300000 / 500000\n",
      "average reward: 505.2750021297485 average time: 239.95 best_reward: 986.500002630055\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 310000 / 500000\n",
      "average reward: 430.42000175751747 average time: 185.75 best_reward: 986.5000027343631\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 320000 / 500000\n",
      "average reward: 633.9150026287883 average time: 279.7 best_reward: 986.2000050246716\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 446.745002085343 average time: 256.85 best_reward: 810.2000031396747\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 340000 / 500000\n",
      "average reward: 635.2750029820949 average time: 284.25 best_reward: 986.1000023186207\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 350000 / 500000\n",
      "average reward: 507.4850022062659 average time: 336.1 best_reward: 986.4000033140182\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 360000 / 500000\n",
      "average reward: 508.515002143383 average time: 411.9 best_reward: 987.0000045150518\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 582.0750028755516 average time: 292.7 best_reward: 814.9000035449862\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 544.23000237979 average time: 225.35 best_reward: 985.8000036403537\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 390000 / 500000\n",
      "average reward: 578.7350027877837 average time: 240.8 best_reward: 985.9000052511692\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 284.62500145249066 average time: 285.7 best_reward: 727.8000036627054\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 367.0650017891079 average time: 236.1 best_reward: 721.9000029563904\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 618.5600031677634 average time: 254.0 best_reward: 985.9000053852797\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 430000 / 500000\n",
      "average reward: 621.6850028775632 average time: 258.35 best_reward: 986.7000060677528\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 549.2850022230298 average time: 263.6 best_reward: 986.6000032946467\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 450000 / 500000\n",
      "average reward: 650.9600029785186 average time: 296.6 best_reward: 987.5000056475401\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 460000 / 500000\n",
      "average reward: 680.0450029108673 average time: 294.3 best_reward: 988.1000053733587\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 626.8150028724224 average time: 335.8 best_reward: 987.4000047445297\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 838.4450035192073 average time: 369.9 best_reward: 987.2000064477324\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 471.77500228099524 average time: 492.1 best_reward: 983.200003914535\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 438.5550016835332 average time: 492.05 best_reward: 870.1000035703182\n"
     ]
    }
   ],
   "source": [
    "train('./ValueClip', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, value_clip = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a87f26-61fd-401d-a8d2-94b6ea8062ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 235.73500065505505 average time: 135.3 best_reward: 448.2000016346574\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 260.2600009027868 average time: 139.5 best_reward: 530.5000017210841\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 206.01500054523348 average time: 102.55 best_reward: 420.60000163316727\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 207.21500063799323 average time: 114.0 best_reward: 420.9000003486872\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 50000 / 500000\n",
      "average reward: 300.53500077798964 average time: 172.35 best_reward: 982.6000002324581\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 283.205000821501 average time: 163.55 best_reward: 527.7000023797154\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 221.26500078476965 average time: 119.3 best_reward: 728.1000036820769\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 220.00500062555074 average time: 111.85 best_reward: 447.40000063180923\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 292.5150008432567 average time: 162.95 best_reward: 595.9000020697713\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 258.3600005224347 average time: 150.85 best_reward: 446.6000005453825\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 311.4950009405613 average time: 180.1 best_reward: 492.10000259429216\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 230.720000917837 average time: 136.35 best_reward: 446.3000023216009\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 236.7150005482137 average time: 126.8 best_reward: 491.9000002592802\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 274.8450007796288 average time: 166.35 best_reward: 594.9000015109777\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 313.07500111535194 average time: 145.05 best_reward: 576.8000018596649\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 286.81500101313 average time: 141.15 best_reward: 577.8000013306737\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 280.405001142621 average time: 155.35 best_reward: 529.0000025257468\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 353.4800014659762 average time: 170.95 best_reward: 530.1000025421381\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 442.59500166885556 average time: 206.25 best_reward: 596.3000020086765\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 449.7700016219169 average time: 242.35 best_reward: 807.6000019907951\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 467.13000184595586 average time: 220.05 best_reward: 596.7000025063753\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 424.03000180386005 average time: 178.35 best_reward: 576.7000022158027\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 259.2150009512901 average time: 644.45 best_reward: 493.5000022724271\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 429.9950019434094 average time: 181.1 best_reward: 578.5000027567148\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 374.1700015645474 average time: 230.25 best_reward: 647.3000026643276\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 489.73000208102167 average time: 239.3 best_reward: 647.4000032246113\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 249.74500089921057 average time: 432.3 best_reward: 596.5000024065375\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 429.0300017550588 average time: 193.0 best_reward: 594.8000017404556\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 346.89000148400663 average time: 253.2 best_reward: 597.9000030532479\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 307.67500124424697 average time: 358.7 best_reward: 578.6000025570393\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 310000 / 500000\n",
      "average reward: 439.9350020132959 average time: 199.35 best_reward: 985.2000038996339\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 320000 / 500000\n",
      "average reward: 537.9200023472309 average time: 270.75 best_reward: 981.4000029265881\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 330000 / 500000\n",
      "average reward: 419.36500171534715 average time: 193.2 best_reward: 985.6000026538968\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 340000 / 500000\n",
      "average reward: 382.81500173285605 average time: 185.55 best_reward: 987.6000026464462\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 350000 / 500000\n",
      "average reward: 581.5250026639551 average time: 263.25 best_reward: 985.5000043734908\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 332.5150014769286 average time: 159.1 best_reward: 728.4000027254224\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 370000 / 500000\n",
      "average reward: 441.69000177979467 average time: 196.15 best_reward: 984.4000010788441\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 412.640001822263 average time: 181.25 best_reward: 986.0000042766333\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 290.25000117346644 average time: 165.85 best_reward: 595.2000027894974\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 398.20000170953574 average time: 190.1 best_reward: 726.7000028416514\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 412.13500185757874 average time: 174.45 best_reward: 985.9000018462539\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 368.5050015963614 average time: 151.15 best_reward: 729.1000009700656\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 430000 / 500000\n",
      "average reward: 472.3300019040704 average time: 209.1 best_reward: 984.6000024750829\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 455.380002034083 average time: 209.8 best_reward: 814.1000040024519\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 450000 / 500000\n",
      "average reward: 481.86000188663604 average time: 230.55 best_reward: 983.5000013038516\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 460000 / 500000\n",
      "average reward: 381.9150017619133 average time: 162.6 best_reward: 984.9000065103173\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 385.52000177018346 average time: 156.15 best_reward: 729.8000023663044\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 457.04500194303694 average time: 217.45 best_reward: 986.3000043779612\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 324.4850014351308 average time: 134.3 best_reward: 729.7000030353665\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 500000 / 500000\n",
      "average reward: 554.1550023149699 average time: 263.35 best_reward: 986.8000029847026\n"
     ]
    }
   ],
   "source": [
    "train('./DogWaterModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb777a-704d-4fac-be8f-d45e44226950",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Possibly reward scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad54c9c-948b-40d2-908d-2c6aceeaf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameter space noising for exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
